# Summary

Basically, the scraper is not bad and serves its purpose. Basic structures were followed, but you quickly noticed that there is not so much coding experience here. In the context of the module itself, I would say that the project was successful. Based on the evaluation scheme, which placed great emphasis on clean code, the project was okay to good.

# Good things
 
* The scraper works and retrieves the data
* The code is structured and easy to understand (good variable names, no confusing splits, comments are there for context etc.)
* Proxies are used, even though most likely overkill for this project. But it may be useful for bigger scraping goals.

# Improvements

I created a few issues and solved them in issue branches. The following list is a summary of the changes I made:
* Improved structure by adding more functions and splitting up the code into smaller parts
* Some slight error logging tweaking
* Utilizing regex for easier data extraction
* Added directories src and logs
* Added requirements.txt and gitignore

You can check out the issues and corresponding branches to better understand the changes I made.
